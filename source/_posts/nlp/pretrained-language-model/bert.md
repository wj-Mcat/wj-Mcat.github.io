title: 关于Bert的一切
tags:
  - nlp
  - bert
categories:
  - nlp
  - pretrained-language-model
author: wj-Mcat
date: 2021-04-28 11:13:00
---
作为NLP领域里程碑式的作品，对于其深刻的理解是很多后续学习工作的基础，更是面试找工作的利器。

<!-- more -->

# 介绍

`bert`是一个基于海量无结构化文本进行深度双向语义建模的预训练模型，通过`Mask Language Model`和`Next Sentence Prediction`两种训练任务，学习到文本中丰富的先验知识。实践证明，这些通用先验知识能够应用于各种下游任务，并取得`SOTA`效果，即使是在`low-resource`下也能够取得良好的效果。

## 整体结构


## 训练方法

### Mask Language Model

### Next Sentence Prediction
